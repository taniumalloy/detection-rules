name: Sync Elastic and VCS Dev Rules

on:
  workflow_dispatch:
    inputs:
      space:
        description: 'Specify the Kibana space to export rules from'
        required: false
        default: 'dev'

jobs:
  fetch-dev-rules:
    runs-on: ubuntu-latest

    steps:
      - name: Checkout repository
        uses: actions/checkout@v3

      - name: Setup Python
        uses: actions/setup-python@v4
        with:
          python-version: 3.9

      - name: Install dependencies
        run: pip install requests

      - name: Fetch and save rules from dev space
        env:
          KIBANA_HOST_DEV: ${{ secrets.KIBANA_HOST }}
          KIBANA_USER: ${{ secrets.DR_KIBANA_USER }}
          KIBANA_PASSWORD: ${{ secrets.DR_KIBANA_PASSWORD }}
        run: |
          python <<EOF
          import os
          import requests
          import json
          from pathlib import Path
          
          # Environment variables
          DEV_URL = f"{os.environ['KIBANA_HOST_DEV']}/s/dev/api/detection_engine/rules/_find"
          AUTH = (os.environ['KIBANA_USER'], os.environ['KIBANA_PASSWORD'])
          HEADERS = {"kbn-xsrf": "true"}
          RULES_DIR = Path("custom_rules/dev")

          def fetch_rules(url):
              """Fetch all rules from the given Elastic Cloud space."""
              rules = []
              page = 1

              while True:
                  response = requests.get(
                      url, headers=HEADERS, auth=AUTH, params={"page": page, "per_page": 100}
                  )
                  response.raise_for_status()
                  data = response.json()

                  rules.extend(data["data"])
                  if page >= data["total_pages"]:
                      break
                  page += 1

              return rules

          def save_rules(rules):
              """Clear and save rules to the custom_rules/dev directory."""
              if RULES_DIR.exists():
                  for file in RULES_DIR.glob("*"):
                      file.unlink()  # Remove all files in the directory

              RULES_DIR.mkdir(parents=True, exist_ok=True)

              for rule in rules:
                  rule_id = rule["rule_id"]
                  file_path = RULES_DIR / f"{rule_id}.json"

                  with open(file_path, "w") as file:
                      json.dump(rule, file, indent=2)

              print(f"Saved {len(rules)} rules to {RULES_DIR}")

          def main():
              dev_rules = fetch_rules(DEV_URL)
              save_rules(dev_rules)

          if __name__ == "__main__":
              main()
          EOF

      - name: Commit and push changes
        run: |
          git config --global user.name "GitHub Actions"
          git config --global user.email "actions@github.com"
          git add custom_rules/dev
          git commit -m "Sync dev rules from Elastic Cloud" || echo "No changes to commit"
          git push
