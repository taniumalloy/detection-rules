name: Manually Sync Rules from Elastic Security to GitHub

on:
  workflow_dispatch:
    inputs:
      pr_sync_rules_from_elastic:
        description: 'Sync rules from Elastic Security (direct commit (false) vs PR (true))'
        required: true
        default: 'true'
      space:
        description: 'Specify the Kibana space to export rules from'
        required: false
        default: 'dev'

jobs:
  manual-dispatch-sync:
    runs-on: ubuntu-latest
    env:
      CUSTOM_RULES_DIR: ${{ secrets.CUSTOM_RULES_DIR }}

    steps:
    - name: Checkout Repository
      uses: actions/checkout@v2

    - name: Set up Python 3.12
      uses: actions/setup-python@v2
      with:
        python-version: '3.12'

    - name: Install Dependencies
      run: |
        python -m pip install --upgrade pip
        pip cache purge
        pip install .[dev]

    - name: Sync Rules from Elastic to GitHub
      env:
        KIBANA_HOST: ${{ secrets.KIBANA_HOST }}
        DR_KIBANA_USER: ${{ secrets.DR_KIBANA_USER }}
        DR_KIBANA_PASSWORD: ${{ secrets.DR_KIBANA_PASSWORD }}
      run: |
        import os
        import requests
        import yaml
        from pathlib import Path

        # Elastic API endpoint
        def get_rules(space):
            url = f"{os.environ['KIBANA_HOST']}/s/{space}/api/detection_engine/rules/_export"
            headers = {"kbn-xsrf": "true"}
            auth = (os.environ['DR_KIBANA_USER'], os.environ['DR_KIBANA_PASSWORD'])
            rules = []

            page = 1
            while True:
                response = requests.get(url, headers=headers, auth=auth, params={"page": page, "per_page": 100})
                response.raise_for_status()
                data = response.json()
                rules.extend(data['data'])

                if len(data['data']) < 100:
                    break
                page += 1

            return rules

        # Paths
        custom_rules_path = Path("custom_rules")
        custom_rules_path.mkdir(exist_ok=True)

        # Sync rules
        for space in ["dev", "prod"]:
            rules = get_rules(space)
            space_path = custom_rules_path / space
            space_path.mkdir(exist_ok=True)

            # Update or create rules
            existing_files = set(space_path.glob("*.yaml"))
            current_files = set()

            for rule in rules:
                rule_id = rule['rule_id']
                rule_file = space_path / f"{rule_id}.yaml"
                current_files.add(rule_file)

                with open(rule_file, "w") as f:
                    yaml.dump(rule, f)

            # Remove deleted rules
            for obsolete_file in existing_files - current_files:
                obsolete_file.unlink()

        # Check for changes
        if os.system("git status --porcelain"):
            os.system("git config user.name 'github-actions'")
            os.system("git config user.email 'github-actions@github.com'")
            os.system("git add .")
            os.system("git commit -m 'Sync rules from Elastic to GitHub' || echo 'No changes to commit.'")
            os.system("git push")
